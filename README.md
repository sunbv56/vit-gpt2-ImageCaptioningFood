
---

# ViT-GPT2 for Image Captioning (Food)

This project implements an image captioning model using a combination of Vision Transformer (ViT) and GPT-2. The model generates captions for food images using a dataset collected from BBC Good Food. The project includes the code for fine-tuning the ViT-GPT2 model and a web interface to deploy the image captioning system. The model was fine-tuned using a GPU environment, and the trained model is available for public use.

## Project Description

The project consists of two main parts:

1. **Fine-tuning the ViT-GPT2 Model**: The file `52100322.ipynb` contains the code for fine-tuning the ViT-GPT2 model. The model is trained to generate descriptive captions for food images. The fine-tuning process utilizes the dataset `22k_FoodCaptionData_bbcgoodfood.csv` and leverages the power of ViT for image feature extraction and GPT-2 for generating captions.

2. **Web Interface Deployment**: The files `client.html` (the front-end) and `server.py` (the back-end) provide a simple user interface to interact with the image captioning model. The web interface allows users to upload food images and receive captions generated by the fine-tuned model.

## Project Structure

- **52100322.ipynb**:
  - Data preprocessing for training.
  - Fine-tuning the ViT-GPT2 model for food image captioning.
  - Saving the fine-tuned model for use in the image captioning system.

- **web/client.html**:
  - A simple user interface for uploading food images and displaying the generated captions.

- **web/server.py**:
  - The back-end code that interacts with the trained model and serves the image captioning predictions to the front-end.

- **data/22k_FoodCaptionData_bbcgoodfood.csv**:
  - The dataset used for fine-tuning the model, which contains food images and their corresponding captions.

- **data/load_data_api.py**:
  - Helper script for loading and preparing the dataset for training.

## Setting Up the Environment

1. **Clone the repository**:
   ```
   git clone https://github.com/sunbv56/Vit-GPT2-ImageCaptioningFood.git
   cd Vit-GPT2-ImageCaptioningFood
   ```

2. **Install the required libraries**:
   After setting up a virtual environment, install the necessary libraries using the following command:

   ```
   pip install -r requirements.txt
   ```

## Training the Model

1. **Open the `52100322.ipynb` file**:
   - Use Jupyter Notebook or Google Colab to open and run the notebook.
   - The notebook will guide you through the process of fine-tuning the ViT-GPT2 model for food image captioning.
   - The model is trained on a dataset from BBC Good Food, which contains food images paired with captions.

2. **Run the entire notebook** to train the model:
   - From data preprocessing to fine-tuning the model.
   - After training, the model will be saved for deployment.

## Deploying the Web Interface

1. **Run the Web Interface**:
   - After fine-tuning the model, you can use the `client.html` and `server.py` files to deploy the web interface for generating food image captions.
   - To start the back-end, run `server.py` using Python.
   - The front-end (`client.html`) will allow users to upload food images, and the server will respond with captions generated by the fine-tuned model.

2. **Sending requests from HTML**:
   - The web interface sends image data to the server, where the model processes the image and generates a caption.

## Libraries Used

- **transformers**: The main library for working with GPT-2 and ViT models.
- **torch**: Deep learning framework used for model training and inference.
- **matplotlib, seaborn**: For visualizing results during analysis and evaluation.
- **pandas**: For data manipulation and handling CSV files.
- **flask**: For running the web server and handling requests between the front-end and back-end.
- **PIL**: Python Imaging Library for processing images.
- **requests**: For interacting with external APIs in the back-end.

## Contributing

Contributions are welcome! If you find any issues, have suggestions for improvements, or want to add new features, please create an issue or submit a pull request.

---
